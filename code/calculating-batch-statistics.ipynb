{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculating batch statistics\n",
    "\n",
    "\n",
    "In this notebook we'll calculate statistics based on the data recieved from sensors. It'll be further used to build predictive models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, we need to import some libraries and initialize Spark:\n",
    "\n",
    "from os.path import join\n",
    "\n",
    "import findspark\n",
    "findspark.init('/home/alex/spark-2.4.3-bin-hadoop2.7')\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName('calc-stats').getOrCreate()\n",
    "\n",
    "from pyspark.sql.functions import concat, col, lit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's import data from all the files from the _processed_ directory. We know that all the files are of the same format so we ask Spark to infer data types and to use header:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Equipment: string (nullable = true)\n",
      " |-- Sensor: string (nullable = true)\n",
      " |-- DateTime: timestamp (nullable = true)\n",
      " |-- Batch: string (nullable = true)\n",
      " |-- Status: integer (nullable = true)\n",
      " |-- Value: double (nullable = true)\n",
      " |-- StringValue: string (nullable = true)\n",
      " |-- Delta: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data = spark.read.csv(join('..','data','processed'), inferSchema=True, header=True)\n",
    "data.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sometimes it's convenient to use SQL syntax. For example, using SQL, we can calculate such statistics as maximum, minimum, average and standard deviation of the signal for every batch, equipment, status and sensor:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize data view\n",
    "data.createOrReplaceTempView(\"data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---------+------+------+-------------------+------------------+------------------+------------------+\n",
      "| Batch|Equipment|Status|Sensor|          min_value|         max_value|         avg_value|         std_value|\n",
      "+------+---------+------+------+-------------------+------------------+------------------+------------------+\n",
      "|B10001|     EQ01|     0| POWER| 0.8166018352206666|234.52915671993958|118.44601031257261| 67.97115667939978|\n",
      "|B10001|     EQ01|     0|  TEMP|0.13629972554137326| 7.204119708946687| 3.695704560097333|1.8595244777380584|\n",
      "|B10001|     EQ02|     0| POWER| 0.5490865080468417| 196.7394043401826| 94.57460402295054|58.499911873289314|\n",
      "|B10001|     EQ02|     0|  TEMP| 1.3258145430902477|231.63468740045474|117.05393107947519|  67.7050913745392|\n",
      "|B10001|     EQ02|     1| POWER| 0.6868167974953926|145.83674862401526| 71.56339880605131|41.278839209071364|\n",
      "|B10001|     EQ02|     1|  TEMP|0.40395794914323024| 65.23380018446827| 33.79116209768979| 18.59236338906267|\n",
      "|B10001|     EQ02|     2| POWER|  0.560560721831199| 60.44572509201104|30.129716125294017|17.200770747040774|\n",
      "|B10001|     EQ02|     2|  TEMP| 0.8535380540261546| 230.3199343535081|119.06172362414013| 65.30496150957713|\n",
      "|B10001|     EQ03|     0| POWER| 0.2060085592214812|52.747768584198035|25.647175949288318|15.451636313868777|\n",
      "|B10001|     EQ03|     0|  TEMP| 0.7627633485921386| 27.45330702617233|14.109806339382622| 7.769082436205977|\n",
      "|B10002|     EQ01|     0| POWER|0.12791689439997234| 54.82507686379673| 26.67812197275319|15.400713755811658|\n",
      "|B10002|     EQ01|     0|  TEMP|0.15875894773020682|152.98336604854603| 76.44977126000418| 44.54457703877829|\n",
      "|B10002|     EQ02|     0| POWER|0.01986560635990497| 59.24495791903485| 29.91972637764166|  17.3299447818536|\n",
      "|B10002|     EQ02|     0|  TEMP| 2.6715467536769917| 253.7890190803286|130.72707495170567| 73.43404770472564|\n",
      "|B10002|     EQ02|     1| POWER| 0.5512370532104673|106.35281270564444| 51.56565117957555|30.438657523732598|\n",
      "|B10002|     EQ02|     1|  TEMP| 0.7480056729028342|242.07738587989914| 124.3255556397309| 72.77086916034625|\n",
      "|B10002|     EQ02|     2| POWER| 1.1799732516937331|  237.564395602799|118.39030786364651| 69.96824102961939|\n",
      "|B10002|     EQ02|     2|  TEMP| 0.3487601421382882|194.07671953145044| 96.03450034342893|55.731320219764136|\n",
      "|B10002|     EQ03|     0| POWER| 0.4360837552825279|25.283133727618083|12.697325300307652|   7.1744762865857|\n",
      "|B10002|     EQ03|     0|  TEMP| 0.2871004800006357| 211.7260705160957|103.12508260454467| 62.32390979562285|\n",
      "+------+---------+------+------+-------------------+------------------+------------------+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql('''\n",
    "    SELECT Batch, Equipment, Status, Sensor,\n",
    "           min(Value) min_value, max(Value) max_value,\n",
    "           avg(Value) avg_value, std(Value) std_value FROM data\n",
    "    WHERE Sensor <> 'BATCH' AND Sensor <> 'STATUS'\n",
    "    GROUP BY Batch, Equipment, Status, Sensor\n",
    "    ORDER BY Batch, Equipment, Status, Sensor\n",
    "''').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will store all the calculation in the specific format: batch, statistic description (feature), value. That way it will be easy to just append newly calculated statistics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+------------------+-------------------+\n",
      "| Batch|           Feature|              Value|\n",
      "+------+------------------+-------------------+\n",
      "|B10001|EQ01_ST0_POWER_min| 0.8166018352206666|\n",
      "|B10001| EQ01_ST0_TEMP_min|0.13629972554137326|\n",
      "|B10001|EQ02_ST0_POWER_min| 0.5490865080468417|\n",
      "|B10001| EQ02_ST0_TEMP_min| 1.3258145430902477|\n",
      "|B10001|EQ02_ST1_POWER_min| 0.6868167974953926|\n",
      "|B10001| EQ02_ST1_TEMP_min|0.40395794914323024|\n",
      "|B10001|EQ02_ST2_POWER_min|  0.560560721831199|\n",
      "|B10001| EQ02_ST2_TEMP_min| 0.8535380540261546|\n",
      "|B10001|EQ03_ST0_POWER_min| 0.2060085592214812|\n",
      "|B10001| EQ03_ST0_TEMP_min| 0.7627633485921386|\n",
      "|B10002|EQ01_ST0_POWER_min|0.12791689439997234|\n",
      "|B10002| EQ01_ST0_TEMP_min|0.15875894773020682|\n",
      "|B10002|EQ02_ST0_POWER_min|0.01986560635990497|\n",
      "|B10002| EQ02_ST0_TEMP_min| 2.6715467536769917|\n",
      "|B10002|EQ02_ST1_POWER_min| 0.5512370532104673|\n",
      "|B10002| EQ02_ST1_TEMP_min| 0.7480056729028342|\n",
      "|B10002|EQ02_ST2_POWER_min| 1.1799732516937331|\n",
      "|B10002| EQ02_ST2_TEMP_min| 0.3487601421382882|\n",
      "|B10002|EQ03_ST0_POWER_min| 0.4360837552825279|\n",
      "|B10002| EQ03_ST0_TEMP_min| 0.2871004800006357|\n",
      "+------+------------------+-------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql('''\n",
    "    SELECT Batch, concat(Equipment,'_ST',Status,'_',Sensor,'_min') as Feature,\n",
    "           min(Value) Value FROM data\n",
    "    WHERE Sensor <> 'BATCH' AND Sensor <> 'STATUS'\n",
    "    GROUP BY Batch, Equipment, Status, Sensor\n",
    "    ORDER BY Batch, Feature\n",
    "''').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate min, max, avg and std for every batch, equipment, status, sensor\n",
    "\n",
    "tables = []\n",
    "\n",
    "for stat in ['min', 'max', 'avg', 'std']:\n",
    "    tables.append(spark.sql(\n",
    "    '''\n",
    "        SELECT Batch, concat(Equipment,'_ST',Status,'_',Sensor,'_{}') as Feature,\n",
    "               {}(Value) Value FROM data\n",
    "        WHERE Sensor <> 'BATCH' AND Sensor <> 'STATUS'\n",
    "        GROUP BY Batch, Equipment, Status, Sensor\n",
    "        ORDER BY Batch, Feature\n",
    "    '''.format(stat,stat)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is also possible to make aggregation without SQL. We will calculate weighted average that way:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "weighted_avg =\\\n",
    "    data.filter(\"Sensor <> 'BATCH' and Sensor <> 'STATUS'\")\\\n",
    "        .withColumn('WeightedValue', data.Value*data.Delta)\\\n",
    "        .groupBy(['Batch', 'Equipment', 'Status', 'Sensor'])\\\n",
    "        .agg({'Delta': 'sum', 'WeightedValue': 'sum'})\\\n",
    "        .withColumn('Feature',concat(col('Equipment'),\\\n",
    "                                    lit('_ST'),col('Status'),\n",
    "                                    lit('_'),col('Sensor'),\n",
    "                                    lit('_weighted_avg')))\\\n",
    "        .withColumn('Value', col('sum(WeightedValue)')/col('sum(Delta)'))\\\n",
    "        .select(['Batch','Feature','Value'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------------------+------------------+\n",
      "| Batch|             Feature|             Value|\n",
      "+------+--------------------+------------------+\n",
      "|B10054|EQ01_ST0_TEMP_wei...| 34.99804995898578|\n",
      "|B10343|EQ02_ST1_TEMP_wei...| 73.91405720706193|\n",
      "|B10351|EQ03_ST0_POWER_we...| 31.97015157990611|\n",
      "|B10245|EQ03_ST0_TEMP_wei...| 43.37907305008837|\n",
      "|B10221|EQ02_ST1_TEMP_wei...| 41.29693787053319|\n",
      "|B10463|EQ03_ST0_POWER_we...|44.597730362606804|\n",
      "|B10450|EQ02_ST0_TEMP_wei...| 105.4038662090142|\n",
      "|B10119|EQ01_ST0_POWER_we...| 18.58378329510701|\n",
      "|B10372|EQ02_ST1_TEMP_wei...|124.37761547134666|\n",
      "|B10272|EQ02_ST2_TEMP_wei...| 44.61103544930486|\n",
      "|B10178|EQ01_ST0_POWER_we...| 9.578686596026547|\n",
      "|B10150|EQ03_ST0_TEMP_wei...|17.705416541740906|\n",
      "|B10430|EQ02_ST0_POWER_we...|127.91370735573052|\n",
      "|B10396|EQ03_ST0_POWER_we...| 5.485610202610873|\n",
      "|B10403|EQ03_ST0_POWER_we...|30.579866432372835|\n",
      "|B10306|EQ03_ST0_POWER_we...| 24.88337710662018|\n",
      "|B10086|EQ02_ST0_POWER_we...|142.56863785675816|\n",
      "|B10091|EQ02_ST0_TEMP_wei...|103.75044164685785|\n",
      "|B10093|EQ02_ST2_POWER_we...| 76.64850897201231|\n",
      "|B10182|EQ02_ST0_POWER_we...| 97.10826362509684|\n",
      "+------+--------------------+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "weighted_avg.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# append all statistics\n",
    "features = tables[0].union(tables[1]).union(tables[2]).union(tables[3]).union(weighted_avg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, features data should be pivoted. After that we transform the result to pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_pd = features.groupBy('Batch').pivot('Feature').avg('Value').toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we save it as a csv file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_pd.to_csv(join('..','data','features.csv'), index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
